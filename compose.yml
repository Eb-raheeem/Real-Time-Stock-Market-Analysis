services:
  spark-master:
    image: spark:3.5.1-python3
    container_name: spark-master
    command: [ "/opt/spark/bin/spark-class", "org.apache.spark.deploy.master.Master", "--host", "spark-master", "--port", "7077", "--webui-port", "8080" ]
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
    ports:
      - "8081:8080" # Spark master communication port
      - "7077:7077" # Spark Web UI
    volumes:
      - spark-data:/opt/spark-data
    networks:
      - stock_data

  # ----------------------------------------------------------------------------------
  spark-worker:
    image: spark:3.5.1-python3
    container_name: spark-worker
    command: [ "/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077", "--webui-port", "8081" ]
    environment:
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
    depends_on:
      - spark-master
    volumes:
      - spark-data:/opt/spark-data
    networks:
      - stock_data

  # ----------------------------------------------------------------------------------------

  kafka:
    image: confluentinc/cp-kafka:7.4.10
    container_name: kafka
    hostname: kafka
    environment:
      KAFKA_KRAFT_MODE: "true" # Enable KRaft mode (no Zookeeper)
      KAFKA_NODE_ID: 1
      KAFKA_LISTENERS: PLAINTEXT_EXTERNAL://0.0.0.0:9094,PLAINTEXT_INTERNAL://kafka:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_INTERNAL://kafka:9092,PLAINTEXT_EXTERNAL://localhost:9094
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093" # Controller ID and endpoint
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"
      CLUSTER_ID: "2XEHiTIZTiuhgUr8z4FkfA"
    ports:
      - "9092:9092" # Broker port
      - "9094:9094" # Controller port
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - stock_data

  # -------------------------------------------------------------------------------------------
  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:v0.7.2
    ports:
      - 8085:8080
    depends_on:
      - kafka
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      DYNAMIC_CONFIG_ENABLED: 'true'
    networks:
      - stock_data

  #---------------------------------------------------------------------------------------------
  consumer:
    build:
      context: ./consumer
      dockerfile: Dockerfile
    image: stream_consumer
    container_name: consumer
    depends_on:
      - spark-master
      - kafka
    restart: unless-stopped
    volumes:
      - ivy_cache:/opt/spark/work-dir/.ivy2
      - ./consumer:/opt/spark/work-dir/apps
    networks:
      - stock_data
  # ----------------------------------------------------------------------------------------------
  postgres:
    image: debezium/postgres:17
    container_name: postgres_db
    restart: unless-stopped
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: stock_data
    ports:
      - "5434:5432"
    volumes:
      - postgres_data:/var/lib/postgres/data
    networks:
      - stock_data

  pgadmin:
    image: dpage/pgadmin4:9
    container_name: pgadmin
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    depends_on:
      - postgres
    networks:
      - stock_data

# -------------- VOLUME AND NETWORK ---------------------------------------------------
volumes:
  spark-data:
  kafka_data:
  ivy_cache:
  postgres_data:


networks:
  stock_data:


